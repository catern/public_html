#+TITLE: The Unix process API is bad (DRAFT)
#+options: num:nil
#+HTML_HEAD: <style type="text/css">body{ max-width:50em; margin-left:auto; margin-right:auto; }</style>
# add a license? CC-BY-SA?

The Unix process API is bad.
All the Unix-like systems of today have the same problems;
none of them have fixed the problems that they inherited from their ancestors.
In this article, though, I'll just be talking about the Linux process API;
it has all the problems of the rest.

Here, when I say "process API", I am talking about the interface
for starting processes,
monitoring processes until they exit,
and stopping processes that haven't yet exited.

And note that I won't be complaining about the fork/exec split;
there's already enough uncontroversial problems without considering that controversial one.

So what is so bad about the Linux process API?

- It makes it easy for processes to accidentally "leak", and linger on the system without anyone to cause them to exit.
- Conversely, it makes it /impossible/ (without root) to guarantee that a buggy or malicious process has not "leaked" some processes.
- It uses global process identifiers (pids) instead of a secure unforgeable identifier,
  making it possible to confuse one process for another.
- It uses signals to communicate process events,
  making libraries (which can't safely handle signals) unable to spawn processes,
  as well as inheriting all the other problems of Unix signals.

I'll explain each problem, as well as some possible solutions that are ultimately flawed.
At the end of the article, I'll go over my own solution and how it solves all of these problems.

But first, some motivation.
Why should we care about flaws in the Linux process API?
Things work well enough right now, don't they?

No, they don't work well enough.
There are many hacks that are justified in part because they fix the badness of this process API.
Hacks like process supervisor daemons, Linux containers, and other generally inflexible tools,
all "fix" parts of the process API,
by providing their own abstraction.

These tools often have other benefits as well, of course.
But if we just focus on the low-level process API on its own and fix it,
we can re-evaluate these hacks and decide if,
in the presence of a good process API,
their other benefits are still worth the cost;
or if those tools might be redesigned to be less complex and more flexible,
if they were working on top of a quality process API.

* It's easy for processes to leak

What do I mean by a "leaked process"?

I mean a process running without anyone knowing where it came from or what it is for.
If we don't know where a process came from or what it's for,
we don't know whether it's safe to kill it,
and it's leaked.
"Leak" is used by analogy with "memory leak";
a memory leak results in memory that isn't really being used,
but is kept alive because there's no way to know it's truly no longer in use.

Once some processes have been leaked,
you have two choices.
You can hope that they will exit on their own at some point.
Or you can manually look at the list of processes running on the system, and try to guess which ones are no longer needed.

There are two requirements for a process to exist without anyone knowing what it is:
First, the process must be orphaned;
second, no-one must know the pid of the process, or have other means to kill precisely that process.[fn:process_groups]

Some process is orphaned when its parent process exits.
If process A starts process B, which starts process C,
and then process B exits,
process C will be orphaned.[fn:easyleakexample]
The parent process B is able to robustly track the lifetime of its child process C,
through the mechanisms Linux provides for parent processes,
and ensure that process C exits.
If C is orphaned, that mechanism is no longer usable,[fn:reparented]
and we have to resort to using C's pid to track it.

If B writes down the pid of process C in some persistent way,
or C writes down its own pid,
we will at least be able to try and kill C later by reading that pid back.
Killing C through its pid has other flaws which will be discussed later,
but it works at a basic level.
But if the pid of process C is not noted down in some persistent way,
we've got a leaked process.
** Flawed solutions
*** Make sure B always cleans up on exit and kills C
B should just always make sure to kill process C before it exits.
That way no processes will be orphaned, so no processes will be leaked, and we'll be fine.

Well, what are the possible ways B might exit and need to clean up?

B might choose to exit, possibly by throwing an exception or panicking.
In those cases, it's possible for B to kill process C immediately before exiting.

Or B might receive a signal.
B might be signaled for conventional reasons,
such as a user pressing Ctrl-C,
in which case B can still clean up, as long as the programmer or runtime take care to catch every kind of signal.

Or B might be signaled for some more unconventional reasons,
such as a segmentation fault.
It's still possible for B to clean up in this case, but it may be very tricky to do,
and the programmer or runtime may need to take great care
to make sure that the pid of C is still accessible even while handling a segfault.

Or B might receive SIGKILL.
Unfortunately, this case prevents this solution from working.
It's not possible for B to clean up when it receives SIGKILL,
so C will be unavoidably leaked.

We might want to say, "never send SIGKILL".
But that is impossible, both for a conventional reason and an ironic reason.
The conventional reason is that B might have a bug, and hang, and SIGKILL might be the only way to kill it.
The ironic reason is that the only way for B to clean up and exit in guaranteed finite time is for it to SIGKILL its own children,
so that if they have bugs they will not just hang forever.
So B would be SIGKILL'd by its own parent, implementing the same strategy.

So, in summary, it's not possible to guarantee that B cleans up and kills C when it exits,
because it might be SIGKILL'd.
Even in the case where B isn't SIGKILL'd,
it's tricky for a complicated program to always make sure to kill off any child processes when it exits.
*** Always write down the pid of every process you start, or coordinate between A and B
B could make sure to always write down the pid of every process it starts, so things can be orphaned but not leaked.
More generally, B could coordinate with A, and somehow tell A about every process B starts.
This will fail if there's a bug in B, or if B is killed just after starting a process but before telling A,
but perhaps it's good enough?

This would work out, if we controlled the entire tree of programs we are running.
Then we could add this coordination to every program we run.

But what if the programs for A and B come from different developers?
Are we going to patch B to do this coordination?
In general, are we going to patch every program in existence that wasn't written by us, to coordinate with us?

It's not practical to rewrite every Unix program in existence.
We want to make it harder for processes to accidentally leak;
but it will still be easy to write or use a program that doesn't follow our coordination mechanism,
and thereby leak processes.
*** A should run B inside a container
If A runs B inside a Linux container technology,
such as a Docker container,
then no matter how many processes B starts,
A will be able to terminate them all by just stopping the container, and we'll be fine.

Ignoring the other merits of containers,
if we're trying to solve the problem of "it is too easy for processes to leak",
containers have four main flaws.

Flaw one is that it's not easy to run a container.

Python has a "subprocess.run" function in its standard library,
for starting a subprocess.
Python has no "container.run" function in its standard library,
to start a subprocess inside a container,
and in the current container landscape that seems unlikely to change.

Shell scripts make starting processes trivial,
but it's almost unthinkable that, say, bash, would integrate functionality for starting containers,
so that every process is started in a container.
Leaving aside the issues of which container technology to use,
it would be quite complex to implement.

Flaw two is that it requires root privileges.
The syscalls required to start a Linux container require you to have root.
There are ways to get around this in recent Linux kernels[fn:user_namespaces],
but they are pretty dubious from a security perspective.

Flaw three is that it's not trivially nestable.
What if I have a hierarchy of 5 processes, ABCDE, each starting the next one in the chain?
Each one has to start its child in a new container,
but nesting containers is still tricky business that can cause breakage.

Flaw four is that it's pretty heavyweight to require literally every child process to run in a separate container.
Containers are heavier than normal processes,
and this will place a real burden on the system.

So, running every child process in a separate container isn't a viable solution.
We still have no way to easily prevent child processes from leaking.
* It's impossible to prevent malicious processes leaks

What's a "malicious process leak"?

Well, if a "process leak" is a process existing on the system without someone knowing to kill it,
a "malicious process leak" is a process existing on the system and actively evading being killed.

A process can fork repeatedly to make a thousand copies of itself,
or just fork constantly at all times, leaving the previous processes to immediately exit,
so that its pid is constantly changing and the latest copy can't be identified and sent a signal.
A "fork bomb" is one example of an attack of this kind.

But note that this doesn't have to be the result of an attack;
simple buggy code can cause this.
If you ever program using fork(),
you could easily start forking repeatedly just from a bug.
** Flawed solutions
*** Run your possibly-malicious process inside a container or a virtual machine
If we run our possibly-malicious process inside a container or virtual machine,
then no matter how much it forks and exits,
we will be able to terminate the process by just stopping the container (or virtual machine).

This will actually work, to a degree.
Most of our earlier concerns (it's too hard, it's heavyweight, and it's not trivially nestable)
no longer apply,
because in this section we're happy to have any means at all to prevent the attack.

However,
it still requires root access to a run a container or a virtual machine.
So this solution is not truly general purpose;
we can't use this routinely, every time we create a child process,
because our application certainly should not run with root access in the normal case.

We can partially get around the need for root access
by having a privileged daemon start processes on our behalf inside a container.[fn:systemd-run]

But having someone else start a process on our behalf breaks a lot of traditional Unix features.
For example, we can't easily have our child process inherit stdin/stdout/stderr from us,
nor will it inherit environment variables or any ulimits we've placed on ourself.
The shell, among other applications, is completely dependent on these features.

Also, this privileged daemon centralizes all the processes we start on the system.
We can't, say, set up a truly isolated environment for development or integration testing,
because we'll still have to go through the central daemon.

So as a general-purpose mechanism,
this is not workable,
but it can work in certain constrained scenarios.
*** Limit the number of processes that can exist on the system
What if we limit the number of processes that can exist on the system?
Then as the process keeps forking,
it will eventually exhaust the available process space and stop,
and in that frozen moment of tranquility,
an already-started process would be able to kill it.

The number of processes that can exist is actually already limited;
there's a maximum pid, and we can't have any more processes than that.
The issue is that as processes exit,
possibly due to being killed by us,
their space is usually freed up,
and new processes can be created.

So if the malicious process just keeps forking,
it can fill up the space left by previous processes exiting,
and this doesn't help us.
Stricter limits on the number of processes can prevent fork bombs,
but not more general attacks.

However, if we could prevent space from being freed up as processes exit,
the space that malicious process has to operate in would shrink and shrink,
until finally it is no longer able to fork any more, and we can kill the last copy.
Preventing the reuse of process space while under possible attack
can be done using a technique that I'll discuss at the end of this article.
It's a key part of a robust solution to the process leaking problem.
* Processes have global, reusable IDs

A process is identified using its 'pid'.
A pid is an integer, frequently in the range 1 to 65536,
which is selected for the process at startup from the pool of currently unused pids,
and which is relinquished back into that pool when the process exits.

There is a single pool of process IDs on the system.
If enough processes are started and exit,
a process ID will be reused.

Pids are mainly used to send signals to processes with the "kill" system call
(which is used for any kind of signal, not just lethal ones).

Typically, a long-lived process (a "daemon") would write its own pid into a file, called a "pidfile".
Then other processes could send signals to the daemon by reading that pidfile and using "kill".

But there is absolutely no guarantee that when you "kill", you are sending a signal to the right process.
If the daemon has exited,
and enough processes have started and stopped since then,
the pid in the daemon's pidfile might point to a completely unrelated process.
You might send a fatal signal to something critically important instead of the daemon you meant to send it to!

Fundamentally, any usage of a pid is vulnerable to a [[https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use][time-of-check-to-time-of-use]] race condition.
Since pids are the only way to identify a process,
this means any interaction with processes (other than your own child processes) is inherently racy.
** Flawed solutions
*** Don't reuse pids, use a UUID instead
We could identify processes with some kind of truly globally unique identifier.
Then we wouldn't have race conditions when we try to kill them.

This would work,
but it would be difficult to retrofit onto an existing Unix system:
Many applications assume that pids are the same size as 32-bit ints.

We would also pay an efficiency cost, just because of handling a larger identifier.
It would be unusual for an operating system to provide references to its internal structures with UUIDs,
when it can use more efficient smaller identifiers and provide security through other means.
*** Only send signals to your own child processes
When process A starts process B, and then process B exits, process A is notified.
Furthermore, process B leaves a "zombie process" behind after it exits,
which consumes the pid until process A explicitly acts to get rid of the zombie process.
These two features allow process A to know exactly when it is safe to send signals to B's pid.
So if A stays running for as long as B is running,
and only A sends signals to B,
we can have signals without races.

This works, and is an excellent replacement for pidfiles.
But it doesn't work in all situations.

What if process A exits unexpectedly?
Then we are back in the situation of not being able to kill process B without a race condition.
Furthermore, what if we genuinely want process B to outlive process A?
This is the case whenever we are starting a long-lived process (a daemon), for example.

To support this, instead of forking off a process,
process A could send a request to a long-lived supervisor daemon to start process B, as the supervisor daemon's own child.
The authors of supervisor daemons such as =systemd= or =supervisord=
often urge software developers not to fork off their own long-lived processes;
instead, say the supervisor daemon authors,
we should request that the supervisor daemon fork off long-lived processes on our behalf.[fn:dontdaemonize]

Unfortunately, that has the same issues as discussed in the section on preventing malicious process leaks,
where we considered having a privileged daemon create containers on our behalf.
We can't easily have our child process inherit stdin/stdout/stderr from us,
nor will it inherit environment variables or any ulimits we've placed on ourself.
And this daemon centralizes the processes we start on the system,
so it's difficult to set up isolated test or development environments.

Furthermore, even if we have a supervisor daemon starting processes on our behalf,
this leaves a static parent-child hierarchy which cannot change.
The supervisor daemon cannot, for example, start a new version of itself to upgrade,
without careful use of exec,
as all of its child processes will stop being its children.
Nor can process A initially start up process B as process A's child,
and then later decide that process B should live past process A's exit.

What we need is a way to send signals without races, without forcing a specific parent-child hierarchy.
If we can make the parent-child hierarchy more flexible,
it would work well.
We will use this technique in combination with others as part of a full solution at the end of this article.
* Process exit is communicated through signals
Process exit is communicated to the parent of a process by SIGCHLD.
If process A starts process B, and then process B exits,
process A will be sent the SIGCHLD signal.

Signals are delivered to the entire process, and only one signal handler can be registered for each signal.

So if the main function in process A registers a signal handler for SIGCHLD,
and library L1 in process A starts a process B, when process B exits,
the signal handler of the main function in process A will receive a notification of the exit of a child it never started,
and the library will never be told that its child has exited.

Conversely, if the library L1 registers the signal handler,
and the main function or even another library L2 starts a process B,
then only L1 will be notified when the process exits.

In general, only one part of the program can directly receive signals.
That one part of the program then must forward the signal around to whatever other components desire to receive signals.
If a library has no interface for receiving signal information,
like glibc,
then it can't use child processes.
This is a major inconvenience for both the library developer and the user.
** Flawed solutions
*** Use signalfd
    While signalfd is certainly a great help in dealing with signals on Linux,
    it doesn't actually help deal with the problem of libraries receiving SIGCHLD.
    You could use signalfd to wait for the SIGCHLD signals,
    but you still then need to forward the signals to each library.
*** Chain signal handlers
    Can't we just have one library's signal handler call the next library's signal handler?

    Rather than explain in this article,
    I refer the reader to [[https://www.macieira.org/blog/2012/07/forkfd-part-2-finding-out-that-a-child-process-exited-on-unix/][here]] where it's explained that signal handler chaining can't be done robustly.
    Libraries have high standard for working, even in strange scenarios!
*** Create a standard library for starting children and have everyone use it
    The issue is that multiple libraries want to handle the task of starting and monitoring children.
    Can't we just agree on a single standard library that abstracts over SIGCHLD,
    and have everyone use it?
    We can provide a file descriptor interface, which is increasingly standard on Linux,
    and is easy for libraries to use and monitor.

    It would be near impossible to get every other library that wants to use subprocesses or wants to listen for SIGCHLD
    to use this single standard library.

    There are already plenty of libraries which provide wrappers around SIGCHLD/fork/exec,
    and plenty of code that depends on them.
    We can't just have a flag day and switch everything over to a new library all at once.
    This becomes even more tricky in high-level languages,
    because most languages already come with a higher-level API around spawning processes.

    Still, the idea of providing a file descriptor interface for starting and monitoring children is a good one.
    File descriptors can easily be integrated into an event loop.
    And a file descriptor can be monitored by a library without interfering with the rest of the program,
    using a library's own private event loop or other mechanisms.
    We just need a way to provide that interface that does not interfere with other libraries in the same process.
* How to fix all these problems
  I only know one existing solution that fixes all these problems
  without sacrificing flexibility or generality.

  Use the C utility [[https://github.com/catern/supervise][supervise]] to start your processes;
  for Python, you can use its associated [[https://github.com/catern/supervise/blob/master/python/supervise_api/supervise.py][Python library]].

  Essentially, we delegate the problem of starting and monitoring child processes
  to a small helper program: supervise.
  And it abstracts away the fixes for these problems behind a nicer (but still low-level) interface.
  For a high-level interface, one can use the Python library.
** Problem: It's easy for processes to leak
   Solution: supervise kills all your descendant processes when you exit.

   supervise is passed a pipe to read instructions from on startup,
   and monitors that pipe throughout its (short and simple) lifetime.
   When the parent process exits,
   the pipe will be closed,
   supervise will be notified,
   supervise will kill the descendant processes,
   and then supervise will also exit.

   It's able to find all descendant processes by using =PR_SET_CHILD_SUBREAPER=, a Linux-specific feature.
   If process A starts process B which starts process C,
   and process B exits,
   if process A set =PR_SET_CHILD_SUBREAPER= then process A will become the new parent of process C.
   This allows it to safely kill all descendant processes.
** Problem: It's impossible to prevent malicious processes leaks
   Solution: supervise kills all your descendant processes when you exit, securely and in a guaranteed-to-terminate way.

   It does this using the technique mentioned in the "Limit the number of processes that can exist on the system" section.
   If we don't free up pid space as a malicious process forks and exits,
   eventually the pid space will be exhausted and the malicious process can be cornered and killed.
** Problem: Processes have global, reusable IDs
   Solution: supervise gives you a file descriptor interface to signaling a process.

   To signal the process, you just write to the file descriptor.
   File descriptors are local and unforgeable,
   so it's not possible for the file descriptor to suddenly start pointing at a different instance of supervise,
   wrapping a different process.

   All the descendant processes of supervise will at some point become its direct children,
   thanks to =PR_SET_CHILD_SUBREAPER=,
   so it can safely send them all signals using "kill" and cause them to exit,
   so a supervision hierarchy can be maintained without forcing any specific organization.

   And just like all file descriptors, the supervise file descriptors can be inherited by children or passed over Unix sockets.
   This allows a supervision hierarchy to be rearranged at runtime,
   rather than forcing a static parent-child hierarchy.
** Problem: Process exit is communicated through signals
   Solution: supervise gives you a file descriptor interface to monitor a process for exit.

   In addition to the file descriptor that supervise reads instructions from,
   supervise also accepts a file descriptor to write status changes to.
   You can read and monitor this file descriptor to receive notification of process status changes. 
* How to really fix all these problems in the long term
  Of course, supervise is not a long-term solution.
  Running an additional helper process for every real process you start is an annoying,
  if slight,
  inconvenience and performance loss.
  The correct long-term solution is to actually get this functionality into the Linux kernel.

  See the [[https://lwn.net/Articles/638613/][=CLONE_FD= patchset]] which provided something similar,
  Thiago Macieira's [[https://www.macieira.org/blog/2012/07/forkfd-part-4-proposed-solutions/][series of blog posts on forkfd]],
  the [[https://www.freebsd.org/cgi/man.cgi?query=pdfork&sektion=2][pdfork syscall]] in FreeBSD,
  and the [[http://capsicum-linux.org/][Capsicum for Linux]] effort which has ported pdfork to Linux.

  All these patchsets were a great inspiration to me in writing supervise and in considering the problems of the Linux process API.

  If supervise proves useful enough in userspace,
  its functionality can be implemented in the kernel,
  and the userspace implementation can be discarded.
  Then we can finally have a good process API on Linux.
* Footnotes

[fn:dontdaemonize]
This is the "don't daemonize yourself, don't put yourself into the background" advice,
which has become very common with the rise of system.
It's certainly correct advice, but it's incomplete.

[fn:reparented]
Orphaned processes are in fact "reparented" to pid 1, "init".
Init can wait for processes to die,
but it doesn't have any knowledge about what a given process actually *is*.
So it doesn't help us keep track of which process is which.

[fn:process_groups]
Process groups provide another means to kill a process.
And the controlling tty is yet another way.
But neither of them are fully generic and nestable.
They each allow a single additional layer of hierarchy,
where you can kill all processes in a single group,
or all processes with the same controlling tty.
But if you create a new process group while already inside some process group,
you will just leave your original process group,
and no longer be killed when that group is killed.
The same is true for the controlling tty.
Because they don't fundamentally change the flaws of the process API, I won't go into them here.

[fn:easyleakexample]
Leaking a process is as simple as this:
#+BEGIN_SRC sh
sh -c '{ sleep inf & } &'
#+END_SRC
'sh' is our process A;
it forks off another copy of itself to perform the outer '&', which is our process B;
then 'sleep inf' is our process C.

[fn:user_namespaces]
User namespaces can be used without privileges,
but they've had a lot of vulnerabilities,
so most Linux distributions don't turn that feature on.

[fn:systemd-run]
systemd, for example, with its [[https://www.freedesktop.org/software/systemd/man/systemd-run.html][systemd-run]] API, allows us to request that systemd start up a process for us on the fly.
systemd runs every process in a separate cgroup (which is the underlying container mechanism that we would use),
so it can protect against the malicious process leak problem.
